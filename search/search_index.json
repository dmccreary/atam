{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Architecture Tradeoff Analysis Methodology","text":"<p>Welcome to our ATAM website!</p> <p>This website stores resources for teaching courses on the Architecture Tradeoff Analysis Methodology (ATAM) with NoSQL databases. ATAM was originally developed by Carnegie Mellon University (CMU) for selecting the appropriate architectures for large computer projects.</p> <p>We have adapted ATAM for use in helping organizations find the best database architecture for a business challenge.</p> <p>This site supports our main textbook:</p> <p>Making Sense of NoSQL</p> <p>Please let me know if you have any questions.</p> <p>Dan McCreary on LinkedIn</p>"},{"location":"about/","title":"About the ATAM/NoSQL Project","text":"<p>Early in my career, I worked for Bell Labs. I met a coworker named Bjarne Stroustrup who was the principal driver behind C++. I was also exposed to Objective C when I worked for Steve Jobs at NeXT Computer.  I realized that it really didn't matter what flavor of programming language you used as long as you used good Design Patterns.  This brought me to read about the origin of design patterns and the incredible book A Timeless Way of Building.  The key word here was timeless because it focused on understanding the underlying principles around a topic that didn't vary with the release of the next version of a software system.</p> <p>I resolved to not write a book on the latest bugs in Windows 3.1.  The shelf life of that book was less than six months.  But if I could find the underlying patterns in the way that we represent data, that book would be timeless!</p>"},{"location":"about/#the-day-i-learned-about-exist-db","title":"The Day I Learned about eXist-DB","text":"<p>I had a transformative experience starting around Feb 2, 2007, at 11:40\u202fAM.  That was the exact day and time that my friend Kurt Cagle suggested that I try out the eXist database.  My life was about to take a surprising turn.</p> <p>I was working on a complex forms project where each form \"Save\" had to perform about 45 inserts into a RDBMS.  That process, of shredding the document into individual parts, was very complex and we had allocated six months to that project.</p> <p>But with eXist, we could perform all that work in a single line of code.  I recall staring at that single line for what must have been 20 minutes.  Could it really be this simple?  Why had I never heard about this?  Why did they only teach me about RDBMS systems in college?  How could I have been such a fool?</p> <p>I vowed NEVER to be caught off guard again.  I vowed I would travel the world to know the best way to store knowledge.  That was the basis of a new conference (NoSQL Now!) I helped orchestrate. From that came the book Making Sense of NoSQL which I wrote with my wife, Ann Kelly.</p> <p>But my journey didn't end with the publication of the book.  Granted, I did become an expert at helping companies select databases.  However, to my utter frustration, despite objective evidence, companies often made poor decisions. So I had to start to study why their cognitive bias got in the way.</p>"},{"location":"atam-db-process/","title":"ATAM Database Selection Process","text":"<p>In this section, we take the Standard ATAM Process and modify it for the specialized task of selecting the right database architecture for a project.</p>"},{"location":"atam-process/","title":"Architectural Tradeoff Analysis Method Process","text":"<p>The Architectural Tradeoff Analysis Method (ATAM) is a structured method for evaluating software architecture with respect to multiple quality attributes. Developed by the Software Engineering Institute (SEI) at Carnegie Mellon University, ATAM helps to understand a system's behavior and determine if it has the right architecture to support the goals of the project. Below is a summary of the ATAM process according to the provided image.</p> <p>Goals of the ATAM Process: The primary goals of the ATAM are to:</p> <ol> <li>Identify the consequences of architectural decisions.</li> <li>Identify risks and non-risks associated with the architecture.</li> <li>Assess the tradeoffs in the architectural approach, particularly those involving quality attributes.</li> <li>Provide a framework to make informed decisions that balance these tradeoffs.</li> </ol> <p>Steps of the ATAM Process:</p> <ol> <li> <p>Business Drivers: This step involves understanding the strategic goals and objectives of the business, which will drive the architectural decisions. This includes constraints, functional and non-functional requirements, and aspirations that shape the architecture.</p> </li> <li> <p>Architecture Plan: The architecture plan is the outline or blueprint of the system's architecture. It includes details on the architectural style, patterns, and structural organization.</p> </li> <li> <p>Quality Attributes: Quality attributes are the non-functional requirements such as performance, security, maintainability, and usability that the system must satisfy.</p> </li> <li> <p>Architectural Approaches: These are the strategies or techniques used to address the quality attributes in the architecture plan, including the use of specific design patterns or systems principles.</p> </li> <li> <p>User Stories: User stories provide a high-level description of functionality from an end-user perspective. They help to ensure that the architecture addresses real user needs.</p> </li> <li> <p>Architectural Decisions: This step involves making concrete decisions about the architecture, which are informed by the business drivers, quality attributes, and architectural approaches.</p> </li> <li> <p>Analysis: The analysis is the core of the ATAM, where the architectural decisions are scrutinized. This stage is where the architectural strategies are evaluated against the desired quality attributes through various analysis techniques.</p> </li> </ol> <p>Documents Produced by the ATAM Process:</p> <ol> <li> <p>Tradeoffs: This document captures the analysis of various architectural decisions and their impact on different quality attributes, revealing where compromises are made.</p> </li> <li> <p>Sensitivity Points: These are the points in the architecture that are sensitive to changes. Understanding these helps in predicting the impact of changes on the system's quality attributes.</p> </li> <li> <p>Non-Risks: These are architectural aspects that have been determined not to pose a risk to the project. They are typically well-understood areas with known solutions.</p> </li> <li> <p>Risks: These are potential problems that could threaten the project's success. They might stem from ambitious quality attribute goals, reliance on novel technology, or other uncertainties in the architecture.</p> </li> </ol> <p>Distilled Information: As a result of the ATAM process, distilled information is produced, which encompasses the identified risks, non-risks, sensitivity points, and tradeoffs. This distilled information helps stakeholders make informed decisions about the architecture and the project.</p> <p>Risk Themes: Throughout the ATAM process, certain themes of risk may emerge. These are broad areas of concern that need to be addressed by the project team to ensure the architecture can meet its goals. Risk themes help prioritize subsequent actions and refine the architecture.</p> <p>Impacts: The identified risks, non-risks, sensitivity points, and tradeoffs have direct impacts on the project. The analysis of these impacts is crucial for planning, mitigation, and ensuring that the architecture aligns with the business drivers.</p> <p>In conclusion, the ATAM process is a comprehensive method that assesses software architecture rigorously to ensure it aligns with business goals and adequately addresses quality requirements. The process involves a detailed evaluation of tradeoffs, risks, and non-risks, culminating in a well-informed architectural strategy that is essential for the successful delivery of the software system.</p>"},{"location":"bias/","title":"Cognitive Bias in Database Selection","text":"<p>After attending the Saturn 2013 Conference I was exposed to the use of \"Cognitive Bias\" in software architecture.</p> <p>Here are some examples of cognitive bias I have seen as applied to the world of NoSQL database selection.</p>"},{"location":"bias/#anchoring-bias","title":"Anchoring Bias","text":"<p>The tendency to produce an estimate near a cue amount.</p> <p>Example: \"Our managers were expecting an RDBMS solution so that\u2019s what we gave them.\"</p>"},{"location":"bias/#availability-heuristic","title":"Availability Heuristic","text":"<p>The tendency to estimate that what is easily remembered is more likely than that which is not.</p> <p>Example: ** \"I hear that NoSQL does not support ACID.\" or \"I hear that XML is verbose.\"</p>"},{"location":"bias/#bandwagon-effect","title":"Bandwagon Effect","text":"<p>The tendency to do or believe what others do or believe.</p> <p>Example: \"Everyone else at this company and in our local area uses RDBMSs.\"</p>"},{"location":"bias/#confirmation-bias","title":"Confirmation Bias","text":"<p>The tendency to seek out only that information that supports one's preconceptions.</p> <p>Example: \"We only read posts from the Oracle|Microsoft|IBM groups.\"</p>"},{"location":"bias/#framing-effect","title":"Framing Effect","text":"<p>The tendency to react to how information is framed, beyond its factual content.</p> <p>Example: \"We know of some NoSQL projects that failed.\"</p>"},{"location":"bias/#gamblers-fallacy","title":"Gambler's fallacy","text":"<p>The failure to reset one's expectations based on one's current situation.</p> <p>Example: \"We already paid for our Oracle|Microsoft|IBM license so why spend more money?\"</p> <ul> <li>Also known as: sunk cost bias</li> </ul>"},{"location":"bias/#hindsight-bias","title":"Hindsight Bias","text":"<p>The tendency to assess one's previous decisions as more efficacious than they were.</p> <p>Example \"Our last five systems worked on RDBMS solutions. Why should we change now?\"</p>"},{"location":"bias/#halo-effect","title":"Halo Effect","text":"<p>The tendency to attribute unverified capabilities in a person based on an observed capability.</p> <p>Example: \"Oracle|Microsoft|IBM sells billions of dollars of licenses each year, how could so many people be wrong\". </p>"},{"location":"bias/#representativeness-heuristic","title":"Representativeness Heuristic","text":"<p>The tendency to judge something as belonging to a class based on a few salient characteristics  - \"Our accounting systems work on RDBMS so why not our product search?\"</p>"},{"location":"bias/#references","title":"References","text":"<ol> <li>Cognitive Bias in Database Selection</li> </ol>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"slides/","title":"ATAM Presentations","text":"<p>You can find our presentations on the topic of ATAM and NoSQL here:</p> <p>https://github.com/dmccreary/atam/tree/main/slides.</p> <p>The license for all these slides is Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED).  We always appreciate attribution!</p>"},{"location":"case-studies/amazon-shopping-cart/","title":"Amazon Shopping Cart Failures","text":"<p>The story of Amazon's struggles with their Oracle-based back-end system during the early 2000s, particularly around the busy holiday shopping season, is a significant one in the history of web-scale computing and database management. It highlights the challenges faced by rapidly growing online businesses and the innovative solutions they developed in response.</p>"},{"location":"case-studies/amazon-shopping-cart/#the-problem","title":"The Problem","text":"<p>Around 2002, Amazon, which was rapidly growing, faced significant challenges with its Oracle relational database management system (RDBMS). The primary issues were related to scalability, reliability, and performance, especially during peak times like the holiday shopping season. The Oracle RDBMS, while robust and powerful, was not ideally suited to handle the massive, unpredictable spikes in traffic and transactions that Amazon experienced. This led to:</p> <ol> <li>Slowdowns and Outages: During peak traffic periods, the database struggled to keep up, resulting in slowdowns and outages.</li> <li>Complexity and Cost: Scaling up the Oracle database to meet the demand was complex and expensive.</li> <li>Rigid Schema: The relational model, with its rigid schema, was not flexible enough for Amazon's rapidly evolving and diverse data needs.</li> </ol>"},{"location":"case-studies/amazon-shopping-cart/#amazons-response","title":"Amazon's Response","text":"<p>Faced with these challenges, Amazon began to explore alternatives. Their response involved a fundamental shift in how they managed their data:</p> <ol> <li>Distributed Systems: Amazon moved away from a centralized RDBMS architecture to a distributed system. This approach allowed them to distribute the load across multiple nodes, improving performance and reliability.</li> <li>Microservices Architecture: They adopted a microservices architecture, breaking down their monolithic application into smaller, independent services. Each service could use the most appropriate data storage solution for its needs.</li> <li>Custom Solutions: Amazon started to build its own data storage solutions tailored to their specific requirements.</li> </ol>"},{"location":"case-studies/amazon-shopping-cart/#amazon-dynamodb","title":"Amazon DynamoDB","text":"<p>One of the most significant outcomes of Amazon's efforts to overcome the limitations of traditional RDBMS systems was the creation of Amazon DynamoDB. DynamoDB, introduced in 2012, is a fully managed NoSQL database service provided by Amazon Web Services (AWS). It was designed to address many of the issues that Amazon faced with their Oracle system:</p> <ol> <li>Scalability: DynamoDB can handle large amounts of traffic and data, scaling up or down as needed.</li> <li>Performance: It offers fast and predictable performance, even under massive load.</li> <li>Flexibility: Being a NoSQL database, it allows for more flexible data models, which is suitable for various types of applications and services.</li> <li>Reliability and Availability: DynamoDB provides high availability and durability, storing data across multiple AWS regions and Availability Zones.</li> </ol> <p>In summary, Amazon's move from an Oracle RDBMS to building and eventually offering DynamoDB as a product was a response to the scalability and flexibility challenges they faced. It represents a broader trend in the industry towards distributed, NoSQL databases for web-scale applications.</p>"},{"location":"case-studies/star-process/","title":"The S.T.A.R Process in Writing ATAM Case Studies","text":"<p>We have written hundreds of case studies about how organzations use the ATAM process.  We use the S.T.A.R approach which stands for:</p> <ol> <li>Situation - give context to the case study</li> <li>Task - what was the challenge being addressed</li> <li>Approach - What was the architectural approach?</li> <li>Results - What were the results, both measurable and intangible</li> </ol> <p>Here are some details for each of these sections:</p>"},{"location":"case-studies/star-process/#situation-context","title":"Situation (Context)","text":"<p>This is the backstory where we set the scene and provide the necessary background information. It involves describing the context within which the events or challenges occurred. For a case study, this would include details about the organization, the environment, specific circumstances, or any other relevant information that gives a clear picture of the scenario.</p>"},{"location":"case-studies/star-process/#task-challenge","title":"Task (Challenge)","text":"<p>Next, we outline the specific challenge or problem that needs to be addressed. It's about what needed to be done and why it was important. In a case study, this could involve a key pain point or the goal that the organization was trying to achieve, or a particular obstacle that needed to be overcome.</p>"},{"location":"case-studies/star-process/#architectural-approach","title":"Architectural Approach","text":"<p>In this section, I describe my architectural approach to building a solution. I briefly describe the options on the table and the tradeoff process that I used to select a specific architectural solution. This process details the strategies, processes, or steps taken to tackle the problem. The focus should be on specific actions and why those actions were chosen.</p>"},{"location":"case-studies/star-process/#results","title":"Results","text":"<p>Finally, we present the outcomes of the approach we took. This is where I showcase the results, achievements, and learnings obtained from the experience. It's important to be as quantifiable as possible, using data and specific examples to illustrate the impact of the actions. I focus on easy-to-measure dollar savings and how the organization is repositioned to be more agile in the future.</p> <p>We like this method because it provides a clear and logical structure, ensuring that all essential elements of a story or case are covered. It's particularly effective in making complex information more digestible and compelling, leading the audience through a logical progression from problem to solution.</p>"},{"location":"concepts/","title":"ATAM Database Concepts","text":""},{"location":"concepts/#cross-cutting-concerns","title":"Cross-cutting Concerns","text":"<ul> <li>Performance and Scalability: We will discuss how each type scales and performs under different workloads.</li> <li>Data Integrity and Consistency: We will contrast the approaches to data integrity and consistency, especially compared to ACID properties in RDBMS.</li> <li>Maintenance and Operational Complexity: We will evaluate the maintenance needs and operational complexity of each type.</li> <li>Security: We cover security features and concerns relevant to each database type.  We put a focus on scalable RBAC systems.</li> <li>Community and Ecosystem: We will also assess the community support, availability of tools, and integration capabilities.</li> <li>Cost Considerations: Next, we discuss cost implications, including open-source versus proprietary solutions and cloud-hosted versus on-premise.</li> <li>Trends and Future Directions: Finally, we iscuss emerging trends in database technologies and potential future developments.</li> </ul>"},{"location":"concepts/#distributed-database-concerns","title":"Distributed Database Concerns","text":"<p>Covering core architectural concepts in distributed databases is essential for understanding their capabilities, challenges, and best use cases. Here are some key concepts you should consider including in your book:</p>"},{"location":"concepts/#distributed-transactions","title":"Distributed Transactions","text":"<ul> <li>ACID Properties in Distributed Context: Explain how Atomicity, Consistency, Isolation, and Durability are maintained across multiple nodes.</li> <li>Two-Phase Commit (2PC): Discuss the two-phase commit protocol as a method of ensuring all-or-nothing transaction execution across distributed systems.</li> <li>Challenges and Trade-offs: Cover challenges like network latency, partition tolerance, and the CAP theorem's implications on distributed transactions.</li> </ul>"},{"location":"concepts/#replication","title":"Replication","text":"<ul> <li>Types of Replication: Describe synchronous and asynchronous replication, their use cases, and trade-offs.</li> <li>Consistency Models: Explain strong versus eventual consistency and their impact on data integrity and system performance.</li> <li>Conflict Resolution: Discuss how conflicts are resolved in multi-master replication scenarios.</li> <li>Replication Topologies: Cover different replication topologies like master-slave, peer-to-peer, and their implications on system resilience and read/write performance.</li> </ul>"},{"location":"concepts/#auto-sharding-data-partitioning","title":"Auto-Sharding (Data Partitioning)","text":"<ul> <li>Concept and Benefits: Explain how auto-sharding distributes data across multiple nodes to balance load and improve performance.</li> <li>Shard Key Selection: Discuss the importance of choosing the right shard key for optimal data distribution and access patterns.</li> <li>Rebalancing and Resharding: Cover the process of redistributing data when adding or removing nodes and its impact on system performance.</li> <li>Challenges: Highlight potential challenges such as hotspots and cross-shard transactions.</li> </ul>"},{"location":"concepts/#high-availability","title":"High Availability","text":"<ul> <li>Redundancy and Failover: Describe how distributed databases achieve high availability through redundancy and automated failover mechanisms.</li> <li>Load Balancing: Explain load balancing strategies for evenly distributing requests and optimizing resource utilization.</li> <li>Disaster Recovery: Discuss strategies for backup and recovery in distributed environments, including geographical distribution for disaster resilience.</li> <li>Monitoring and Health Checks: Cover the importance of monitoring system health and performing regular checks to ensure high availability.</li> </ul>"},{"location":"concepts/#cross-cutting-concepts","title":"Cross-Cutting Concepts","text":"<ul> <li>CAP Theorem: Discuss the CAP Theorem (Consistency, Availability, Partition Tolerance) and its implications for distributed database design.</li> <li>Network Partitioning and Latency: Explain the impact of network issues on distributed databases and strategies to mitigate these effects.</li> <li>Data Consistency Levels: Differentiate between various levels of data consistency (like read-your-writes, monotonic reads, etc.) in distributed systems.</li> <li>Security Considerations: Highlight security challenges unique to distributed databases, including data encryption and secure communication across nodes.</li> </ul>"},{"location":"concepts/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Global Databases and Multi-Region Deployment: Discuss the architecture and considerations for deploying globally distributed databases.</li> <li>Data Versioning and Time Travel Queries: Introduce concepts like data versioning and the ability to query data as it existed at a specific point in time.</li> <li>Observability and Debugging: Address the complexity of monitoring and debugging in distributed environments, emphasizing distributed tracing and log aggregation.</li> </ul> <p>By covering these topics, you'll provide a thorough understanding of the architectural complexities of distributed databases. These concepts are crucial for anyone looking to design, implement, or manage a distributed database system effectively.</p>"},{"location":"concepts/acid-vs-base/","title":"ACID vs. BASE","text":"<p>In this section, we will discuss the concept of ACID versus BASE in the context of distributed database systems. This contrast highlights two fundamentally different approaches to handling data consistency and availability in distributed environments.</p>"},{"location":"concepts/acid-vs-base/#acid-explained","title":"ACID Explained","text":"<p>ACID stands for Atomicity, Consistency, Isolation, and Durability. It is a set of principles aimed at ensuring reliable transaction processing in database systems.</p> <ol> <li>Atomicity: Guarantees that all operations within a transaction are treated as a single unit. Either all operations are executed successfully, or none are.</li> <li>Consistency: Ensures that a transaction brings the database from one valid state to another, maintaining all predefined rules, including constraints, cascades, and triggers.</li> <li>Isolation: Ensures that concurrently executed transactions do not affect each other. Each transaction is isolated from others until it's completed.</li> <li>Durability: Once a transaction is committed, it will remain so, even in the event of system failures. This usually involves writing to non-volatile memory or logs.</li> </ol> <p>ACID in Real-World Systems: Traditional relational databases like PostgreSQL, MySQL, and Oracle are prime examples of systems implementing ACID properties. They are used in scenarios where data integrity and consistency are non-negotiable, such as financial systems, inventory management, and any system where it's critical to prevent data anomalies.</p>"},{"location":"concepts/acid-vs-base/#base-explained","title":"BASE Explained","text":"<p>BASE stands for Basically Available, Soft state, and Eventual consistency. It's an alternative model designed for distributed systems, focusing on high availability and fault tolerance, at the cost of strong consistency.</p> <ol> <li>Basically Available: Indicates that the system guarantees availability in terms of the CAP theorem, but allows for some level of data inconsistency.</li> <li>Soft state: The state of the system may change over time, even without input. This is due to eventual consistency models where data is not immediately consistent across all nodes.</li> <li>Eventual Consistency: The system will eventually become consistent once it stops receiving input. Data replication to achieve consistency can be delayed for better performance and availability.</li> </ol> <p>BASE in Real-World Systems: NoSQL databases like Cassandra, Couchbase, and DynamoDB use the BASE model. They are suitable for applications that can tolerate some degree of inconsistency or where the emphasis is on horizontal scalability and speed, such as social networks, big data analytics, and content distribution networks.</p>"},{"location":"concepts/acid-vs-base/#contrasting-acid-and-base","title":"Contrasting ACID and BASE","text":"<ol> <li>Consistency vs. Availability: ACID prioritizes consistency (every read receives the most recent write) but may sacrifice availability (the system might not always be able to process transactions). BASE, on the other hand, prioritizes availability with the trade-off that data may not always be consistent immediately.</li> <li>System Design: Systems implementing ACID are often more straightforward to reason about but can be challenging to scale horizontally. BASE systems are designed for scale, but they require more complex designs to handle data inconsistency.</li> <li>Use Cases: ACID is essential where consistency is critical, like banking systems. BASE is preferred where scalability and handling high volumes of data with variable consistency is acceptable, like in social media feeds.</li> <li>Network Partitions: In the event of network partitions, ACID systems might stop processing transactions to maintain consistency, while BASE systems will continue to operate, accepting that the data will be inconsistent until the partition resolves.</li> </ol> <p>In summary, the choice between ACID and BASE models in distributed databases depends on the specific requirements of the application, particularly in terms of consistency needs and scalability. Understanding the trade-offs between these models is crucial for designing systems that meet the necessary reliability, availability, and performance criteria.</p>"},{"location":"concepts/utility-tree/","title":"Utility Tree","text":""},{"location":"concepts/utility-tree/#overview","title":"Overview","text":"<p>A Utility Tree, also known as a Quality Tree, is a hierarchical model that represents various quality attributes (often non-functional requirements) that are significant for the success of a software project. It helps stakeholders to prioritize requirements by assessing their importance and the ease with which they can be fulfilled by a given architecture.</p>"},{"location":"concepts/utility-tree/#creating-an-intuitive-measure-of-fitness-for-a-task","title":"Creating an Intuitive Measure of Fitness for a Task","text":"<p>Our goal in creating quality tree diagrams is to create an intuitive visualization of the \"fitness\" of a database for a given application. Think of this as trying to see if a glove fits your hand.  Each finger needs to fit well in the glove.</p> <p>Think of each finger as a \"dimension\" of fitness.  At the end of trying on gloves, you will get an overall feeling of how specific gloves fit.  Our goal is to not focus on just one dimension of fitness, but to get a more holistic feeling for the fitness of the most critical aspects of the suitability of a database for a project.</p>"},{"location":"concepts/utility-tree/#non-functional-requirements-nfrs","title":"Non-Functional Requirements (NFRs)","text":"<p>Non-functional requirements are criteria that specify the operation of a system, as opposed to the behaviors or functions the system must perform. These include aspects like scalability, performance, security, and usability. In the context of databases, NFRs are crucial because they define how the system should behave under various conditions and constraints.</p> <p>Examples of Non-Functional Requirements for a Database:</p> <ol> <li>Scalability: The ability of the database to handle increased loads by adding resources.</li> <li>Availability: The degree to which the database is operational and accessible when required for use.</li> <li>Security: Protection of data against unauthorized access and ensuring confidentiality, integrity, and availability of data.</li> <li>Performance: The speed with which the database processes transactions and returns results.</li> <li>Maintainability: How easily the database can be modified to add new features, fix bugs, or improve performance.</li> </ol> <p>Quality Tree for Database Selection: The image provided exemplifies a Quality Tree where each \"ility\" is a branch representing a key quality attribute of a database. Each attribute is further broken down into specific characteristics that can be evaluated.</p> <p>The \"-ilities\" Listed with Two Scores: Each quality attribute is assessed based on two dimensions:</p> <ol> <li>Importance to the success of the project (I): Ranks how critical the attribute is to the project's success, scored as Critical (C), High (H), Medium (M), or Low (L).</li> <li>Ease of fulfillment by the architecture (E): Measures how easily a given architecture can fulfill the requirement, scored as Easy (E), Medium (M), or Hard (H).</li> </ol> <p>Quality Tree Descriptions Based on the Image:</p> <ol> <li> <p>Scalability (H, L): Critical for handling growth but can be challenging to implement, requiring the architecture to manage data across multiple nodes and support distributed queries.</p> </li> <li> <p>Availability (H, L): High importance for continuous operation, particularly in distributed systems where fault tolerance and automatic data migration to new nodes are essential.</p> </li> <li> <p>Findability (H, L): The ease of locating information via full-text search and customizable ranking is crucial for user satisfaction.</p> </li> <li> <p>Schemaless (H, L): Important for flexibility in handling various data types without predefined models, which can be both a boon and a challenge depending on the use case.</p> </li> <li> <p>Queryability (H, L): A database's capacity to query any data attribute and fit the query language to the problem space is essential for effective data retrieval.</p> </li> <li> <p>Transformability (H, M): The ability to easily write data transformations and distribute them over many servers is critical for data processing but might require moderate effort to implement.</p> </li> <li> <p>Affordability (H, L): Cost is always a consideration; open-source licenses offer significant savings but may vary in ease of integration with existing systems.</p> </li> <li> <p>Interoperability (M, H): The ability to integrate with reporting tools and standardized systems is highly important for a holistic data environment, often facilitated by adherence to standards.</p> </li> <li> <p>Security (H, H): Ensuring robust security measures like role-based access control and audit capabilities is critical and typically requires substantial effort to implement effectively.</p> </li> </ol> <p>In summary, a Quality Tree is a visual representation that helps in the decision-making process when selecting a database for a project. It lays out the NFRs in a structured format, allowing stakeholders to discuss, prioritize, and decide which qualities are most important and how feasible they are to implement with the chosen architecture. This approach enables a balanced assessment of potential trade-offs and ensures that the selected database aligns with the project's goals and constraints.</p>"},{"location":"db-types/","title":"Database Architecture Types","text":"<p>In this section, we will cover the six key database architecture types we use when selecting the right database architecutre.</p> <p></p> <p>The six types are:</p> <ol> <li>Relational</li> <li>Analytical (OLAP Cubes)</li> <li>Key Value Stores</li> <li>Column Family Stores</li> <li>Graph</li> <li>Document</li> </ol> <p>Each of these database architectures have many sub-types and each of these have pros and cons for different applications.</p> <p>It today's AI-driven world, graphs have become a major force. We will cover this topic in the next section.</p>"},{"location":"db-types/03-key-value/","title":"Key Value Stores","text":"<p>Simplify, simplify, simplify. Henry David Thoreau</p> <p>Simplicity is the ultimate sophistication. Leonardo da Vinci</p> <p>Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away. \u2014Antoine de Saint-Exup\u00e9ry, author of The Little Prince</p> <p>Any intelligent fool can make things bigger, more complex and more violent. It takes a touch of genius and a lot of courage to move in the opposite direction.  \u2014Albert Einstein</p>"}]}